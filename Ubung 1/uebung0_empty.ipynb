{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e47bc91",
   "metadata": {},
   "source": [
    "# Aufgabe -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28477df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc00dc2",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c14c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zwei Sequenzen mit gleichem Seed\n",
    "def generate_uniform_sequence(seed, size=10000):\n",
    "    np.random.seed(seed)\n",
    "    return np.random.uniform(0, 1, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3552b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "sequence1 = generate_uniform_sequence(seed)\n",
    "sequence2 = generate_uniform_sequence(seed)\n",
    "print(\"Erste 5 Werte mit gleichem Seed:\")\n",
    "print(\"Sequenz 1:\", sequence1[:5])\n",
    "print(\"Sequenz 2:\", sequence2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717faab",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0050d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zwei Sequenzen mit unterschiedlichen Seeds\n",
    "seed1 = 42\n",
    "seed2 = 99\n",
    "sequence3 = generate_uniform_sequence(seed1)\n",
    "sequence4 = generate_uniform_sequence(seed2)\n",
    "print(\"\\nErste 5 Werte mit unterschiedlichen Seeds:\")\n",
    "print(\"Sequenz 3 (Seed 42):\", sequence3[:5])\n",
    "print(\"Sequenz 4 (Seed 99):\", sequence4[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305222e",
   "metadata": {},
   "source": [
    "## c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm, Mittelwert und Varianz\n",
    "def plot_histogram_and_stats(sequence, title):\n",
    "    plt.hist(sequence, bins=30, density=True, alpha=0.6, color='b')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Wert')\n",
    "    plt.ylabel('Dichte')\n",
    "    plt.show()\n",
    "    empirical_mean = np.mean(sequence)\n",
    "    empirical_var = np.var(sequence)\n",
    "    theoretical_mean = 0.5\n",
    "    theoretical_var = 1/12\n",
    "    print(f'Empirischer Mittelwert: {empirical_mean}, Theoretischer Mittelwert: {theoretical_mean}')\n",
    "    print(f'Empirische Varianz: {empirical_var}, Theoretische Varianz: {theoretical_var}')\n",
    "\n",
    "print(\"\\nStatistiken für Sequenz 1:\")\n",
    "plot_histogram_and_stats(sequence1, 'Histogramm der Sequenz 1 (Seed 42)')\n",
    "print(\"\\nStatistiken für Sequenz 4:\")\n",
    "plot_histogram_and_stats(sequence4, 'Histogramm der Sequenz 4 (Seed 99)') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81051d6",
   "metadata": {},
   "source": [
    "# Intermezzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57919e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import bernoulli, binom, poisson, norm, expon\n",
    "from scipy.stats import gamma, beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa908fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rng = np.random.default_rng(np.random.PCG64(42))\n",
    "N = 50_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa3387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Diskret ---\n",
    "# Bernoulli(p=0.3): E=p, Var=p(1-p)\n",
    "p = 0.3\n",
    "x = bernoulli.rvs(p, size=N, random_state=rng)\n",
    "print(\"Bernoulli\")\n",
    "print(\"Simulation: mean/var ~\", x.mean(), x.var(ddof=1))\n",
    "print(\"Theorie:              \", p, p*(1-p))\n",
    "print(\"\")\n",
    "\n",
    "# Binomial(n=10,p=0.4): E=np, Var=np(1-p)\n",
    "n, pb = 10, 0.4\n",
    "x = binom.rvs(n, pb, size=N, random_state=rng)\n",
    "print(\"Binomial\")\n",
    "print(\"Simulation:  mean/var ~\", x.mean(), x.var(ddof=1))\n",
    "print(\"Theorie:               \",  n*pb, n*pb*(1-pb))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Poisson(lam=3): E=Var=lam\n",
    "lam = 3\n",
    "x = poisson.rvs(lam, size=N, random_state=rng)\n",
    "print(\"Poisson\")\n",
    "print(\"Simulation:   mean/var ~\", x.mean(), x.var(ddof=1))\n",
    "print(\"Theorie:                \", lam, lam)\n",
    "print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e884273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stetig ---\n",
    "# Normal(0,1): E=0, Var=1\n",
    "z = rng.standard_normal(N)\n",
    "print(\"Standardnormal\")\n",
    "print(\"Simulation:    mean/var ~\", z.mean(), z.var(ddof=1))\n",
    "print(\"Theorie:                 \", 0, 1)\n",
    "print(\"\")\n",
    "\n",
    "# Exponential(lam=1): E=1, Var=1\n",
    "e = expon.rvs(scale=1.0, size=N, random_state=rng)\n",
    "print(\"Exponential\")\n",
    "print(\"Simulation:     mean/var ~\", e.mean(), e.var(ddof=1))\n",
    "print(\"Theorie:                  \", 1, 1)\n",
    "print(\"\")\n",
    "\n",
    "# Gamma(k=3, theta=2): E=k*theta, Var=k*theta^2\n",
    "g = gamma.rvs(a=3, scale=2.0, size=N, random_state=rng)\n",
    "print(\"Gamma\")\n",
    "print(\"Simulation:     mean/var ~\", g.mean(), g.var(ddof=1))\n",
    "print(\"Theorie:                  \",  3*2, 3*(2**2))\n",
    "print(\"\")\n",
    "\n",
    "# Beta(2,5): E=2/7, Var=alpha*beta/[(alpha+beta)^2*(alpha+beta+1)]\n",
    "b = beta.rvs(a=2, b=5, size=N, random_state=rng)\n",
    "theo_mean = 2/7\n",
    "theo_var  = 2*5/((7**2)*8)\n",
    "print(\"Beta\")\n",
    "print(\"Simulation:      mean/var ~\", b.mean(), b.var(ddof=1))\n",
    "print(\"Theorie:                   \", theo_mean, theo_var)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ffae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Beispielplot: Normal (PDF über Histogramm) ---\n",
    "xs = np.linspace(-4, 4, 401)\n",
    "plt.figure()\n",
    "plt.hist(z, bins=60, density=True, alpha=0.6, \n",
    "    edgecolor=\"k\", label=\"Empirisch\")\n",
    "plt.plot(xs, norm.pdf(xs, 0, 1), lw=2, label=\"PDF Normal(0,1)\")\n",
    "plt.title(\"Normalverteilung: Histogramm + PDF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2c5a6",
   "metadata": {},
   "source": [
    "# Aufgabe -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c14c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3b811",
   "metadata": {},
   "source": [
    "## a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ab4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_cdf_exponential(lam, size=1000):\n",
    "    U = np.random.uniform(0, 1, size)\n",
    "    X = - (1 / lam) * np.log(1 - U)\n",
    "    return X\n",
    "\n",
    "# Parameter\n",
    "lambda_param = 1.0\n",
    "sample_size = 10000\n",
    "\n",
    "# Generieren der Stichprobe\n",
    "samples = inverse_cdf_exponential(lambda_param, sample_size)\n",
    "\n",
    "# Validierung\n",
    "plt.hist(samples, bins=30, density=True, alpha=0.6, color='orange', label='Empirisch')\n",
    "x = np.linspace(0, np.max(samples), 1000)\n",
    "plt.plot(x, expon.pdf(x, scale=1/lambda_param), 'r-', lw=2, label='Theoretisch')\n",
    "plt.title('Exponentialverteilung via Inverse-CDF')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Dichte')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittelwert und Varianz\n",
    "empirical_mean = np.mean(samples)\n",
    "empirical_var = np.var(samples)\n",
    "theoretical_mean = 1 / lambda_param\n",
    "theoretical_var = 1 / (lambda_param ** 2)\n",
    "print(f'Empirischer Mittelwert: {empirical_mean}, Theoretischer Mittelwert: {theoretical_mean}')\n",
    "print(f'Empirische Varianz: {empirical_var}, Theoretische Varianz: {theoretical_var}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f70612",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b2c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_cdf_discrete(categories, probabilities, size=1000):\n",
    "    U = np.random.uniform(0, 1, size)\n",
    "    cumulative_prob = np.cumsum(probabilities)\n",
    "    samples = []\n",
    "    for u in U:\n",
    "        for i, cp in enumerate(cumulative_prob):\n",
    "            if u < cp:\n",
    "                samples.append(categories[i])\n",
    "                break\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f76bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategorien und Wahrscheinlichkeiten\n",
    "categories = ['A', 'B', 'C', 'D']\n",
    "probabilities = [0.1, 0.2, 0.3, 0.4]\n",
    "# Generieren der Stichprobe\n",
    "discrete_samples = inverse_cdf_discrete(categories, probabilities, sample_size)\n",
    "# Validierung\n",
    "counts = Counter(discrete_samples)\n",
    "empirical_freq = {cat: counts[cat] / sample_size for cat in categories}\n",
    "print('Empirische Häufigkeiten:', empirical_freq)\n",
    "print('Theoretische Wahrscheinlichkeiten:', {cat: prob for cat, prob in zip(categories, probabilities)})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balkendiagramm (gruppiert)\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "empirical_values = [empirical_freq[cat] for cat in categories]\n",
    "theoretical_values = probabilities\n",
    "plt.bar(x - width/2, empirical_values, width, label='Empirisch')\n",
    "plt.bar(x + width/2, theoretical_values, width, label='Theoretisch')\n",
    "plt.xticks(x, categories)\n",
    "plt.legend()\n",
    "plt.ylabel('Häufigkeit')\n",
    "plt.title('Diskrete Kategorievariable via Inverse-CDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d64da6",
   "metadata": {},
   "source": [
    "# Aufgabe -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49acd499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0796c",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Ziehen aus einer kategorialen Verteilung\n",
    "def sample_categorical(labels, probs, size=1000):\n",
    "    U = np.random.uniform(0, 1, size)\n",
    "    cumulative_prob = np.cumsum(probs)\n",
    "    samples = []\n",
    "    for u in U:\n",
    "        for i, cp in enumerate(cumulative_prob):\n",
    "            if u < cp:\n",
    "                samples.append(labels[i])\n",
    "                break\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b871f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validierung\n",
    "labels = ['A', 'B', 'C', 'D']\n",
    "probs = [0.1, 0.2, 0.3, 0.4]\n",
    "sample_size = 100000\n",
    "samples = sample_categorical(labels, probs, sample_size)\n",
    "counts = Counter(samples)\n",
    "empirical_freq = {label: counts[label] / sample_size for label in labels}\n",
    "print('Empirische Häufigkeiten:', empirical_freq)\n",
    "print('Theoretische Wahrscheinlichkeiten:', {label: prob for label, prob in zip(labels, probs)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb83e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balkendiagramm\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "empirical_values = [empirical_freq[label] for label in labels]\n",
    "theoretical_values = probs\n",
    "plt.bar(x - width/2, empirical_values, width, label='Empirisch')\n",
    "plt.bar(x + width/2, theoretical_values, width, label='Theoretisch')\n",
    "plt.xticks(x, labels)\n",
    "plt.xlabel('Kategorien')\n",
    "plt.ylabel('Wahrscheinlichkeit')\n",
    "plt.title('Empirische vs Theoretische Wahrscheinlichkeiten')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66adc6f1",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden einer Seite mit p ∝ (1,1,1,1,3)\n",
    "labels_dice = [1, 2, 3, 4, 5, 6]\n",
    "probs_dice = [1, 1, 1, 1, 1, 3]\n",
    "probs_dice = np.array(probs_dice) / sum(probs_dice)\n",
    "# Ziehen von 100000 Seiten\n",
    "dice_samples = sample_categorical(labels_dice, probs_dice, sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ce21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Empirische Erwartung\n",
    "empirical_mean_dice = np.mean(dice_samples)\n",
    "# Theoretische Erwartung\n",
    "theoretical_mean_dice = sum(label * prob for label, prob in zip(labels_dice, probs_dice))\n",
    "print(f'Empirischer Erwartungswert der Seite: {empirical_mean_dice}')\n",
    "print(f'Theoretischer Erwartungswert der Seite: {theoretical_mean_dice}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b515b251",
   "metadata": {},
   "source": [
    "# Aufgabe -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc401ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "n = 100  # Anzahl der Kartentypen\n",
    "b = 10   # Karten pro Booster\n",
    "N = 100000  # Anzahl der Booster\n",
    "rng = np.random.default_rng(seed=42)  # Zufallszahlengenerator mit Seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c506c48",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Öffnen eines Boosters mit Zurücklegen\n",
    "def open_booster_uniform(n, b, rng):\n",
    "    return rng.integers(1, n + 1, size=b).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869fffc",
   "metadata": {},
   "source": [
    "## c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a569b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulieren von Boostern mit Zurücklegen\n",
    "all_boosters_uniform = [open_booster_uniform(n, b, rng) for _ in range(N)]\n",
    "# Flatten der Liste und Zählen der Kartentypen\n",
    "flat_uniform = [card for booster in all_boosters_uniform for card in booster]\n",
    "counts_uniform = Counter(flat_uniform)\n",
    "empirical_freq_uniform = {card: counts_uniform[card] / (N * b) for card in range(1, n + 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a71c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm für Boosters mit Zurücklegen\n",
    "plt.bar(empirical_freq_uniform.keys(), empirical_freq_uniform.values())\n",
    "plt.xlabel('Kartentyp')\n",
    "plt.ylabel('Empirische Häufigkeit')\n",
    "plt.title('Empirische Häufigkeiten der Kartentypen (mit Zurücklegen)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a339fec",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65818095",
   "metadata": {},
   "source": [
    "## Erweiterung (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ccdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Öffnen eines Boosters ohne Zurücklegen\n",
    "def open_booster_without_replacement(n, b, rng):\n",
    "    return rng.choice(np.arange(1, n + 1), size=b, replace=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e38bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulieren von Boostern ohne Zurücklegen\n",
    "all_boosters_without_replacement = [open_booster_without_replacement(n, b, rng) for _ in range(N)]\n",
    "# Flatten der Liste und Zählen der Kartentypen\n",
    "flat_without_replacement = [card for booster in all_boosters_without_replacement for card in booster]\n",
    "counts_without_replacement = Counter(flat_without_replacement)\n",
    "empirical_freq_without_replacement = {card: counts_without_replacement[card] / (N * b) for card in range(1, n + 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c925a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Histogramm für Boosters ohne Zurücklegen\n",
    "plt.bar(empirical_freq_without_replacement.keys(), empirical_freq_without_replacement.values())\n",
    "plt.xlabel('Kartentyp')\n",
    "plt.ylabel('Empirische Häufigkeit')\n",
    "plt.title('Empirische Häufigkeiten der Kartentypen (ohne Zurücklegen)')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e37f7",
   "metadata": {},
   "source": [
    "# Aufgabe -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a91051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "n = 100  # Anzahl der Kartentypen\n",
    "b = 10   # Karten pro Booster\n",
    "N = 100000  # Anzahl der Booster\n",
    "\n",
    "# Raritäten und ihre Anteile\n",
    "cards = list(range(1, n + 1))\n",
    "rarity_probs = [78/n, 20/n, 2/n] \n",
    "rarities = [\"C\", \"U\", \"R\"]\n",
    "rng = np.random.default_rng(seed=42)  # Zufallszahlengenerator mit Seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce68c9e",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b702388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Öffnen eines Boosters mit gewichteten Kategorien\n",
    "def open_booster_weighted(cards, rarities, rarity_probs, b, rng):\n",
    "    booster_ids = rng.choice(cards, size=b, replace=False).tolist()\n",
    "    \n",
    "    cumulative_prob = np.cumsum(rarity_probs)\n",
    "    samples = []\n",
    "    for j in range(b):\n",
    "        u = rng.uniform(0, 1)\n",
    "        for i, cp in enumerate(cumulative_prob):\n",
    "            if u < cp:\n",
    "                samples.append(\n",
    "                    (booster_ids[j], rarities[i])\n",
    "                    )\n",
    "                break\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5e5fad",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulieren von Boostern mit gewichteten Kategorien\n",
    "all_boosters_weighted = [open_booster_weighted(cards, rarities, rarity_probs, b, rng) for _ in range(N)]\n",
    "\n",
    "# Zählen der Raritäten pro Booster\n",
    "all_boosters_rarity_counters = [Counter([card[1] for card in booster]) for booster in all_boosters_weighted]\n",
    "\n",
    "# Flattening, nur die Rare Karten\n",
    "all_boosters_rare_cards = [Counter.get(\"R\", 0) for Counter in all_boosters_rarity_counters]\n",
    "\n",
    "# Zählen der Raritäten pro Booster\n",
    "rarity_counts = Counter(all_boosters_rare_cards) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69299884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balkendiagramm der Raritätenverteilung von 1 bis 10 (auch wenn der Counter nicht alle Zahlen hat)\n",
    "empirical_values = [rarity_counts.get(i, 0) / N for i in range(0, b + 1)]\n",
    "\n",
    "x = list(range(0, b + 1))\n",
    "plt.bar(x, empirical_values, width, label='Empirisch')\n",
    "plt.xticks(x, x)\n",
    "plt.title('Verteilung der Anzahl an rare Karten pro Booster')\n",
    "plt.ylabel('Wahrscheinlichkeit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68779c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittelwert der Häufigkeit an rare Karten pro Booster\n",
    "empirical_mean_rare = np.mean(all_boosters_rare_cards)\n",
    "theoretical_mean_rare = b * rarity_probs[2]\n",
    "print(f'Empirischer Mittelwert an rare Karten pro Booster: {empirical_mean_rare}')\n",
    "print(f'Theoretischer Mittelwert an rare Karten pro Booster: {theoretical_mean_rare}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72bf83",
   "metadata": {},
   "source": [
    "## Erweiterung (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8933e836",
   "metadata": {},
   "source": [
    "# Aufgabe -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6fb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecacf386",
   "metadata": {},
   "source": [
    "\n",
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04495d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Doppelte pro Booster\n",
    "duplicate_counts = []\n",
    "# aus Aufgabe -3 c)\n",
    "for booster in all_boosters_uniform:\n",
    "    counts = Counter(booster)\n",
    "    # Nur das zweite Auftreten zählt als Duplikat\n",
    "    duplicates = sum(count - 1 for count in counts.values() if count > 1)\n",
    "\n",
    "    duplicate_counts.append(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_counter = Counter(duplicate_counts)\n",
    "empirical_duplicate_values = [duplicate_counter.get(i, 0) / N for i in range(0, b + 1)]\n",
    "x_duplicates = list(range(0, b + 1))\n",
    "plt.bar(x_duplicates, empirical_duplicate_values, width, label='Empirisch')\n",
    "plt.xticks(x_duplicates, x_duplicates)\n",
    "plt.title('Verteilung der Anzahl an Duplikaten pro Booster (mit Zurücklegen)')\n",
    "plt.ylabel('Wahrscheinlichkeit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae99353",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4358d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rarity_probs = [0.78, 0.17, 0.05]  # Neue Wahrscheinlichkeiten\n",
    "# normalisieren der Wahrscheinlichkeiten\n",
    "new_rarity_probs = np.array(new_rarity_probs) / sum(new_rarity_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057077ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulieren von Boostern mit neuen Wahrscheinlichkeiten\n",
    "all_boosters_weighted_new = [open_booster_weighted(cards, rarities, new_rarity_probs, b, rng) for _ in range(N)]\n",
    "# Zählen der Raritäten pro Booster\n",
    "all_boosters_rarity_counters_new = [Counter([card[1] for card in booster]) for booster in all_boosters_weighted_new]\n",
    "# Flattening, nur die Rare Karten\n",
    "all_boosters_rare_cards_new = [Counter.get(\"R\", 0) for Counter in all_boosters_rarity_counters_new]\n",
    "# Zählen der Raritäten pro Booster\n",
    "rarity_counts_new = Counter(all_boosters_rare_cards_new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Balkendiagramm der Raritätenverteilung von 1 bis 10 (auch wenn der Counter nicht alle Zahlen hat)\n",
    "empirical_values_new = [rarity_counts_new.get(i, 0) / N for i in range(0, b + 1)]\n",
    "x_new = list(range(0, b + 1))\n",
    "plt.bar(x_new, empirical_values_new, width, label='Empirisch (p_R=0.05)')\n",
    "plt.xticks(x_new, x_new)\n",
    "plt.title('Verteilung der Anzahl an rare Karten pro Booster (p_R=0.05)')\n",
    "plt.ylabel('Wahrscheinlichkeit')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b02fa",
   "metadata": {},
   "source": [
    "# Aufgabe 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a86e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
